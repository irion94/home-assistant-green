# STT Improvement - Final Recommendation

**Date**: 2025-11-28
**User Priority**: Accuracy first, comprehensive improvements
**Polish-Specific Model**: âœ… AVAILABLE!

---

## ðŸŽ¯ Recommended Solution: Polish Distilled Whisper

I found **THE PERFECT MODEL** for your needs:

### `WitoldG/distil-whisper-large-v3-pl-ct2`

This is a **Polish-optimized Whisper model** that's:
- âœ… **Already converted to CTranslate2 format** (faster-whisper compatible)
- âœ… **Prepared specifically for Home Assistant** faster-whisper add-on
- âœ… **3x faster than standard large-v3** (1-1.5s vs 2-4s)
- âœ… **49% smaller than large-v3** (~1.5GB vs ~3GB)
- âœ… **Trained/optimized for Polish language**
- âœ… **Drop-in replacement** (no code changes needed)

**Source**: [HuggingFace - WitoldG/distil-whisper-large-v3-pl-ct2](https://huggingface.co/WitoldG/distil-whisper-large-v3-pl-ct2)

This is exactly what you need - better accuracy than current "base" model, optimized for Polish, and faster than large-v3!

---

## Implementation Plan

### Phase 1: Model Upgrade (30 minutes)

#### Step 1: Backup Current Configuration
```bash
cd ~/home-assistant-green/ai-gateway
cp docker-compose.yml docker-compose.yml.backup
```

#### Step 2: Update Whisper Model Configuration

**Option A: Use Polish Distilled Model (RECOMMENDED)**
```yaml
# In docker-compose.yml, wake-word service environment:
- WHISPER_MODEL=WitoldG/distil-whisper-large-v3-pl-ct2
```

**Option B: Use Standard Large-V3 (if Option A fails)**
```yaml
- WHISPER_MODEL=large-v3
```

#### Step 3: Download and Test
```bash
# Restart wake-word service (will auto-download model)
docker compose restart wake-word

# Monitor download progress (first time ~1.5GB)
docker compose logs -f wake-word | grep -i "loading\|download\|whisper"

# Wait for: "Whisper model loaded successfully"
```

#### Step 4: Test Recognition
```bash
# Trigger wake-word and say Polish command
# Check transcription quality in logs:
docker compose logs wake-word | grep -i "transcription"
```

---

### Phase 2: Audio Hardware Fix (1-2 hours)

#### Issue: ReSpeaker Beamforming Not Active

**Current Problem**:
- Using channel 0 (raw mic) instead of channel 4 (beamformed)
- ReSpeaker 6-mic array has:
  - Channels 0-3: Raw microphones
  - Channel 4: Beamformed (best quality for voice)
  - Channel 5: Processed with echo cancellation

#### Solution 1: Switch to Beamformed Channel

**File**: `wake-word-service/app/audio_capture.py`

Find line ~152:
```python
# Current: Use first channel (or average channels) for mono
audio_mono = audio[:, 0]  # Channel 0 - RAW MIC
```

Change to:
```python
# Use beamformed channel for better voice isolation
audio_mono = audio[:, 4]  # Channel 4 - BEAMFORMED
```

**Rebuild and restart**:
```bash
cd ~/home-assistant-green/ai-gateway
docker compose build wake-word
docker compose restart wake-word
```

#### Solution 2: Increase Software Gain (if needed)

**File**: `wake-word-service/app/audio_capture.py`

Find line ~156:
```python
gain = 2.0  # Boost by 2x - higher values cause severe clipping
```

Test different values:
```python
gain = 3.0  # Try 3x boost (monitor for clipping)
```

**Monitor audio levels**:
```bash
docker compose logs wake-word | grep "Audio stats"
# Look for: max=XXX (should be 5000-15000, not 32767 = clipping)
```

#### Solution 3: Install ReSpeaker Drivers (if missing)

**On Raspberry Pi host** (not in Docker):
```bash
# Check if seeed-voicecard installed
arecord -l | grep ReSpeaker

# If not found, install drivers:
git clone https://github.com/HinTak/seeed-voicecard
cd seeed-voicecard
sudo ./install.sh

# Reboot
sudo reboot
```

---

### Phase 3: Parameter Tuning (30 minutes)

#### Confidence Threshold Adjustment

**Current**: 0.7 (70% confidence triggers Whisper fallback)

Since we're using Polish-optimized Whisper now, **lower the threshold** to use Whisper more often:

```yaml
# In docker-compose.yml, ai-gateway service:
- STT_CONFIDENCE_THRESHOLD=0.5  # Currently: 0.7
```

**Effect**:
- Vosk < 50% confidence â†’ Use Whisper (more accurate)
- More Whisper usage = better accuracy, slightly slower

#### VAD Parameters (Optional)

If still cutting off speech:

```yaml
# In docker-compose.yml, wake-word service environment:
- VAD_SILENCE_THRESHOLD=800      # More sensitive (currently 1000)
- VAD_SILENCE_CHUNKS=15          # Longer pause (currently 12)
- VAD_MIN_SPEECH_CHUNKS=6        # Shorter min speech (currently 8)
```

---

## Testing Procedure

### Create Baseline Test Set

**20 Polish Test Commands** (record each 3 times):

```
1. "Zapal Å›wiatÅ‚o"
2. "WÅ‚Ä…cz Å›wiatÅ‚o w salonie"
3. "WyÅ‚Ä…cz Å›wiatÅ‚o w kuchni"
4. "Ustaw jasnoÅ›Ä‡ na piÄ™Ä‡dziesiÄ…t procent"
5. "ZmieÅ„ kolor na niebieski"
6. "Jaka jest temperatura w domu"
7. "WÅ‚Ä…cz klimatyzacjÄ™"
8. "WyÅ‚Ä…cz ogrzewanie"
9. "Podgrzej salon"
10. "SchÅ‚Ã³dÅº sypialniÄ™"
11. "WÅ‚Ä…cz telewizor"
12. "WyÅ‚Ä…cz gÅ‚oÅ›nik"
13. "Jaka jest pogoda"
14. "SprawdÅº temperaturÄ™"
15. "PokaÅ¼ zuÅ¼ycie energii"
16. "Porozmawiajmy"
17. "ZakoÅ„cz rozmowÄ™"
18. "Przerwij"
19. "WÅ‚Ä…cz wszystkie Å›wiatÅ‚a"
20. "WyÅ‚Ä…cz wszystkie Å›wiatÅ‚a"
```

### Test Scenarios

1. **Quiet room** (baseline)
2. **Background TV** (noise rejection)
3. **2-3 meters away** (far-field performance)

### Measure Metrics

```bash
# Word Error Rate calculation
# Compare: expected text vs transcribed text

# Sentence Accuracy
successful_commands / total_commands

# Intent Accuracy
correct_actions / total_commands

# Latency
# Time from speech end â†’ transcription complete
docker compose logs wake-word | grep "latency\|duration"
```

---

## Expected Results

### Before (Current State)
- âŒ Accuracy: 0-25% (unusable)
- âŒ Model: faster-whisper-base (142MB)
- âŒ Audio: Raw mic channel 0 (no beamforming)
- âŒ Confidence threshold: 70% (not enough Whisper usage)

### After Phase 1 (Model Upgrade)
- âœ… Accuracy: 50-75% (major improvement)
- âœ… Model: distil-whisper-large-v3-pl-ct2 (~1.5GB, Polish-optimized)
- âœ… Latency: 1-1.5s (acceptable)
- âœ… Polish-specific vocabulary

### After Phase 2 (Audio Fix)
- âœ… Accuracy: 70-85% (beamforming improves SNR)
- âœ… Better far-field recognition
- âœ… Noise rejection improved

### After Phase 3 (Parameter Tuning)
- âœ… Accuracy: 80-90% (target achieved)
- âœ… More consistent performance
- âœ… Complete utterances captured

---

## Rollback Procedures

### If Model Upgrade Fails

```bash
# Revert to original config
cd ~/home-assistant-green/ai-gateway
cp docker-compose.yml.backup docker-compose.yml
docker compose restart wake-word
```

### If Audio Changes Cause Issues

```bash
# Revert audio_capture.py changes
cd ~/home-assistant-green/wake-word-service
git checkout app/audio_capture.py
docker compose build wake-word
docker compose restart wake-word
```

### If VAD Too Aggressive

```bash
# Remove VAD environment variables from docker-compose.yml
# Service will use defaults
docker compose restart wake-word
```

---

## Resource Impact

### RAM Usage
| Component | Before | After | Impact |
|-----------|--------|-------|--------|
| Vosk | 92MB | 92MB | No change |
| Whisper | 142MB | ~1.5GB | +1.4GB |
| **Total** | **234MB** | **~1.6GB** | **âœ… OK for RPi5 8GB** |

### CPU Usage
| Operation | Before | After | Impact |
|-----------|--------|-------|--------|
| Vosk STT | <1s | <1s | No change |
| Whisper STT | 0.5-1s | 1-1.5s | +0.5-1s |
| **Total latency** | **8-13s** | **9-14s** | **âœ… Acceptable** |

### Storage
| Model | Size | Free Space |
|-------|------|------------|
| distil-pl-ct2 | ~1.5GB | âœ… Plenty on SSD |

---

## Alternative Models (If Needed)

### If Polish Distilled Model Not Available

1. **Standard large-v3** (best accuracy, slower):
   ```yaml
   - WHISPER_MODEL=large-v3
   ```
   - Accuracy: â­â­â­â­â­
   - Speed: â­â­ (2-4s)
   - Size: ~3GB

2. **Medium model** (balanced):
   ```yaml
   - WHISPER_MODEL=medium
   ```
   - Accuracy: â­â­â­â­
   - Speed: â­â­â­ (1-2s)
   - Size: ~1.5GB

3. **bardsai/whisper-large-v2-pl** (requires conversion):
   - Fine-tuned for Polish on Common Voice dataset
   - Needs CTranslate2 conversion (complex)
   - Similar performance to distil-pl-ct2

---

## Next Steps

### Immediate Actions (Today)

1. âœ… **Read this plan**
2. âœ… **Approve Phase 1** (model upgrade)
3. â³ **Record baseline test set** (20 commands Ã— 3 = 60 recordings)
4. â³ **Measure current accuracy** (establish baseline)

### Day 1: Model Upgrade

1. â³ Backup configuration
2. â³ Update docker-compose.yml
3. â³ Restart service (download model)
4. â³ Test with same 60 recordings
5. â³ Compare results

### Day 2: Audio Fix

1. â³ Switch to beamformed channel
2. â³ Test recognition improvement
3. â³ Adjust gain if needed
4. â³ Measure far-field performance

### Day 3: Parameter Tuning

1. â³ Lower confidence threshold
2. â³ Test Whisper usage increase
3. â³ Tune VAD if cutting speech
4. â³ Final accuracy test

### Day 4: Validation

1. â³ 100 command test (real-world usage)
2. â³ Different scenarios (quiet/noisy/far)
3. â³ Calculate final WER/accuracy
4. â³ Document configuration

---

## Success Criteria

### Minimum Acceptable
- âœ… 50% accuracy (2x better than current 25%)
- âœ… 70% intent recognition
- âœ… <3s total latency

### Target Goals
- âœ… 75-85% accuracy
- âœ… 85% intent recognition
- âœ… <2s Whisper latency

### Stretch Goals
- âœ… 90%+ accuracy in quiet
- âœ… 75%+ accuracy with noise
- âœ… <1.5s average latency

---

## Questions?

**Q: Will this work with faster-whisper?**
A: YES! The distil-pl-ct2 model is specifically prepared for faster-whisper.

**Q: How much RAM will it use?**
A: ~1.6GB total (Vosk + Whisper), well within RPi5 8GB capacity.

**Q: Can I roll back easily?**
A: YES! All changes are configuration-only in Phase 1. Simple `docker compose restart`.

**Q: What if Polish model doesn't work?**
A: Fallback to standard `large-v3` (still much better than current `base`).

**Q: Will latency be acceptable?**
A: 1-1.5s for Whisper transcription (vs current 0.5-1s). Total: 9-14s including TTS.

**Q: Can I test before committing?**
A: YES! Record baseline, upgrade model, compare. No permanent changes until you confirm improvement.

---

## Summary

**Current State**: 0-25% accuracy with base model + raw mic
**Recommended**: Polish distilled Whisper + beamformed audio + tuned parameters
**Expected Result**: 80-90% accuracy (3-4x improvement)
**Risk**: Low (configuration-only, easy rollback)
**Effort**: 2-4 hours total
**ROI**: High (system becomes actually usable)

**Ready to proceed with Phase 1?** ðŸš€

---

## References

- [WitoldG/distil-whisper-large-v3-pl-ct2](https://huggingface.co/WitoldG/distil-whisper-large-v3-pl-ct2) - Polish Distilled Whisper for faster-whisper
- [faster-distil-whisper](https://github.com/metame-ai/faster-distil-whisper) - CTranslate2 integration
- [Polish Whisper Models Collection](https://huggingface.co/collections/bardsai/polish-whisper) - bards.ai Polish ASR models
- [bardsai/whisper-large-v2-pl](https://huggingface.co/bardsai/whisper-large-v2-pl) - Alternative Polish model
- [BIGOS V2 Benchmark](https://papers.nips.cc/paper_files/paper/2024/file/69bddcea866e8210cf483769841282dd-Paper-Datasets_and_Benchmarks_Track.pdf) - 2024 Polish ASR evaluation
- [ReSpeaker 4-Mic Array](https://wiki.seeedstudio.com/ReSpeaker_4_Mic_Array_for_Raspberry_Pi/) - Beamforming documentation
